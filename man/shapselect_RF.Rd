% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/shapselect_rf.R
\name{shapselect_RF}
\alias{shapselect_RF}
\title{Selection step of shapley forest through SHAP values.}
\usage{
shapselect_RF(
  X,
  y,
  drop_fraction,
  number_selected,
  CLASSIFICATION,
  mtry_factor,
  ntree_factor,
  min_ntree,
  num_processors,
  nodesize,
  cl,
  nsim
)
}
\arguments{
\item{X}{A data.frame. With columns denoting a feature vector.
Could include additional covariates not a part of
the original modules.}

\item{y}{A Response vector.}

\item{drop_fraction}{A value between 0 and 1 representing the percentage of features
to be dropped at each iteration.}

\item{number_selected}{Number of features selected at the end of shapley forest.}

\item{mtry_factor}{Number to adjust \code{mtry} for random forest.
If regression, \code{mtry} is set to
\code{ceiling}(\eqn{\sqrt(p)}*\code{mtry_factor}).
If classication, \code{mtry} is set to
\code{ceiling}((p/3)*\code{mtry_factor}).  If either
of these numbers is greater than p, \code{mtry} is
set to p.}

\item{ntree_factor}{A number greater than 1 to adjust \code{ntree}.  \code{ntree} for each
random is \code{ntree_factor} times the number
of features.  For each random forest, \code{ntree}
is set to \code{max}(\code{min_ntree},
\code{ntree_factor}*\code{p}).}

\item{min_ntree}{Minimum number of trees grown in each random forest.}

\item{num_processors}{Number of processors used to fit random forests.}

\item{nodesize}{Minimum \code{nodesize}}

\item{cl}{Initialized cluster for parallelization. Set \code{cl}
to \code{NULL} if no parallelization is being ran.}

\item{nsim}{Number of Monte Carlo repetitions for estimating SHAP
values in the screening step. Default is \code{1}. Increasing
\code{nsim} leads to more accurate results, but at the cost
of computational cost.}
}
\value{
A data.frame with final surviving features.
}
\description{
Runs the selection step of shapley forest algorithm if \code{shap_type} = "full".
Returns data.frame with the final surviving SHAP values and features.
}
